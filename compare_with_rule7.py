import os
import json
import openai
from datetime import datetime
import logging
import random

def setup_logging(context):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"security_analysis_rule_set_{context}_{timestamp}.log"
    
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    file_handler = logging.FileHandler(log_filename)
    file_handler.setLevel(logging.INFO)
    
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

def call_llm(messages):
    try:
        client = openai.OpenAI(
            api_key=os.environ["OPENAI_API_KEY"],
            base_url=os.environ["OPENAI_API_BASE"]
        )
        response = client.chat.completions.create(
            model="claude-3-5-sonnet",
            messages=messages
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"Exception in call_llm: {str(e)}")
        return None

def parse_json(response):
    try:
        if response.find("```json") >= 0:
            start_pos = response.find("```json") + 7
            end_pos = response.rfind("```")
            response = response[start_pos:end_pos]
        else:
            start_pos = response.find("{")
            end_pos = response.rfind("}")
            response = response[start_pos:end_pos+1]
        return json.loads(response, strict=False)
    except Exception as e:
        print("Exception:", str(e))
        raise e

def load_all_rules(cases):
    all_rules = []
    for case in cases:
        rule_path = os.path.join(case, 'general_rule.json')
        with open(rule_path, 'r') as f:
            rule_data = json.load(f)
        all_rules.append(rule_data['general_rule'])
    return all_rules

def get_rule_set(all_rules, correct_rule):
    rule_set = [correct_rule]
    remaining_rules = [rule for rule in all_rules if rule != correct_rule]
    rule_set.extend(random.sample(remaining_rules, 3))
    random.shuffle(rule_set)
    return rule_set

def analyze_before_code(code_path, rule_set):
    with open(code_path, 'r', encoding='utf-8') as file:
        code = file.read()
    
    prompt = f"""Please analyze the following code and identify the single most severe and certain security risk based on this set of rules:

Rules:
{json.dumps(rule_set, indent=2)}

Code:
{code}

Instructions:
1. Only identify a risk if it is directly and clearly related to one of the given rules.
2. The risk must be highly relevant and certain. If you're not highly confident about the relevance or certainty of a potential risk, do not include it.
3. If no highly relevant and certain risk is found, return an empty list for "risks".
4. If a relevant risk is identified, provide a detailed explanation, including the specific lines of code involved and which rule it violates.
5. Provide the output in the following JSON format:

{{
    "risks": [
        {{
            "description": "Detailed description of the risk",
            "explanation": "Explanation of how this violates the rule, including line numbers and which rule it violates",
            "severity": "high/medium/low",
            "confidence": "high"
        }}
    ]
}}

Remember, it's perfectly acceptable and often preferable to return an empty list if no highly relevant and certain risk is found.
"""
    messages = [{"role": "user", "content": prompt}]
    return call_llm(messages)

def get_all_files(directory):
    file_list = []
    for root, _, files in os.walk(directory):
        for file in files:
            file_list.append(os.path.relpath(os.path.join(root, file), directory))
    return file_list

def process_case(case_path, logger, all_rules):
    before_path = os.path.join(case_path, 'before')
    after_path = os.path.join(case_path, 'after')
    
    before_file = get_all_files(before_path)[0]
    after_file = get_all_files(after_path)[0]
    
    before_code_path = os.path.join(before_path, before_file)
    after_code_path = os.path.join(after_path, after_file)

    # Load the correct rule for this case
    rule_path = os.path.join(case_path, 'general_rule.json')
    with open(rule_path, 'r') as f:
        correct_rule = json.load(f)['general_rule']

    # Generate rule set
    rule_set = get_rule_set(all_rules, correct_rule)

    logger.info(f"Processing case: {case_path}")
    logger.info(f"Using rule set: {json.dumps(rule_set, indent=2)}")

    # Step 1 & 2: Analyze before code and log results
    logger.info("Analyzing before code...")
    before_analysis = analyze_before_code(before_code_path, rule_set)
    logger.info(f"Before analysis result:\n{before_analysis}")

    before_risks = parse_json(before_analysis)

    # Combine results
    final_result = {
        "rule_set": rule_set,
        "correct_rule": correct_rule,
        "before_risks": before_risks["risks"],
        "after_analysis": None,
        "overall_assessment": None
    }

    # Only proceed with after analysis if risks were found in the before analysis
    if len(before_risks["risks"]) > 0:
        logger.info("Risks found in before analysis. Proceeding with after analysis...")
        # Step 3: Analyze after code
        after_analysis = analyze_after_code(after_code_path, json.dumps(before_risks, indent=2), rule_set)
        logger.info(f"After analysis result:\n{after_analysis}")

        after_result = parse_json(after_analysis)

        final_result["after_analysis"] = after_result["after_analysis"]
        final_result["overall_assessment"] = after_result["overall_assessment"]
    else:
        logger.info("No risks found in before analysis. Skipping after analysis.")

    logger.info(f"Final result:\n{json.dumps(final_result, indent=2)}")

    return final_result

def analyze_after_code(code_path, before_risks, rule_set):
    with open(code_path, 'r', encoding='utf-8') as file:
        code = file.read()
    
    prompt = f"""Given the following code, the previously identified security risks, and the set of rules:

Rules:
{json.dumps(rule_set, indent=2)}

Previously identified risks:
{before_risks}

Code to analyze:
{code}

Please check if the previously identified security risks still exist in this code. For each risk, state whether it has been fully addressed or still exists. Provide a brief explanation for each.

Output the result in the following JSON format:

{{
    "after_analysis": {{
        "risk1": {{
            "status": "addressed/still_exists",
            "explanation": "brief explanation"
        }},
        "risk2": {{
            "status": "addressed/still_exists",
            "explanation": "brief explanation"
        }},
        "risk3": {{
            "status": "addressed/still_exists",
            "explanation": "brief explanation"
        }}
    }},
    "overall_assessment": "overall security improvement assessment"
}}
"""

    messages = [{"role": "user", "content": prompt}]
    return call_llm(messages)

def analyze_final_result(final_result):
    if final_result['after_analysis'] is None:
        return 0
    remaining_risks = 0
    for risk in final_result['after_analysis'].values():
        if risk['status'] == 'still_exists':
            remaining_risks += 1
    return remaining_risks

def main():
    logger = setup_logging("main")
    logger.info("Starting rule set security analysis process")

    with open('small_file_cases.json', 'r') as f:
        cases = json.load(f)

    # Load all rules
    all_rules = load_all_rules(cases)
    logger.info(f"Loaded {len(all_rules)} rules")

    results = {}
    total_cases = 0
    improved_cases = 0
    total_risks = 0
    fixed_risks = 0
    
    for case in cases:
        try:
            case_result = process_case(case, logger, all_rules)
            results[case] = case_result
            
            # 分析最终结果
            initial_risks = len(case_result['before_risks'])
            remaining_risks = analyze_final_result(case_result)
            fixed_risks_in_case = initial_risks - remaining_risks
            
            logger.info(f"Case {case}: {remaining_risks} out of {initial_risks} risks still exist")
            
            # 更新计数器
            total_cases += 1
            total_risks += initial_risks
            fixed_risks += fixed_risks_in_case
            
            if initial_risks > 0 and remaining_risks < initial_risks:
                improved_cases += 1
            
            # 将剩余风险数添加到结果中
            results[case]['remaining_risks'] = remaining_risks
            
            # 输出当前统计信息
            logger.info(f"Total cases executed: {total_cases}")
            logger.info(f"Cases with improvements: {improved_cases}")
            logger.info(f"Total risks identified: {total_risks}")
            logger.info(f"Total risks fixed: {fixed_risks}")
            
        except Exception as e:
            logger.error(f"Error processing case {case}: {str(e)}")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_filename = f"security_analysis_rule_set_results_{timestamp}.json"
    with open(result_filename, 'w') as f:
        json.dump(results, f, indent=4)

    logger.info("Rule set security analysis process completed")

if __name__ == "__main__":
    main()