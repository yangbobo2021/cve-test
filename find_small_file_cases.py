import os
import json

def count_lines(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
            return sum(1 for line in file)
    except Exception as e:
        print(f"Error counting lines in {file_path}: {e}")
        return 0

def get_all_files(directory):
    file_list = []
    for root, _, files in os.walk(directory):
        for file in files:
            file_list.append(os.path.relpath(os.path.join(root, file), directory))
    return file_list

def filter_small_files(input_file, output_file, max_lines=300):
    with open(input_file, 'r') as f:
        cases = json.load(f)

    filtered_cases = []

    for case in cases:
        before_dir = os.path.join(case, 'before')
        after_dir = os.path.join(case, 'after')

        before_files = get_all_files(before_dir)
        after_files = get_all_files(after_dir)

        if set(before_files) == set(after_files):
            case_valid = True
            for file_name in before_files:
                before_file_path = os.path.join(before_dir, file_name)
                after_file_path = os.path.join(after_dir, file_name)

                before_lines = count_lines(before_file_path)
                after_lines = count_lines(after_file_path)
                # print(f"{file_name}: Before: {before_lines}, After: {after_lines}")

                if before_lines > max_lines or after_lines > max_lines:
                    case_valid = False
                    break

            if case_valid:
                filtered_cases.append(case)

    with open(output_file, 'w') as f:
        json.dump(filtered_cases, f, indent=4)

    print(f"Filtered {len(filtered_cases)} cases out of {len(cases)}.")
    print(f"Results saved to {output_file}")

def main():
    input_file = 'single_file_cases.json'
    output_file = 'small_file_cases.json'
    max_lines = 1000

    filter_small_files(input_file, output_file, max_lines)

if __name__ == "__main__":
    main()